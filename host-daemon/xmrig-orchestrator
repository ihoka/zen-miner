#!/usr/bin/env ruby
# frozen_string_literal: true

# XMRig Orchestrator Daemon
# Polls Rails database for commands and manages XMRig systemd service

require "bundler/inline"

gemfile do
  source "https://rubygems.org"
  gem "sqlite3", "~> 2.4"
  gem "sentry-ruby", "~> 5.22"
end

require "json"
require "net/http"
require "socket"
require "logger"
require "time"
require "open3"
require "sentry-ruby"

# Initialize Sentry if DSN provided
if ENV["SENTRY_DSN"]
  begin
    Sentry.init do |config|
      config.dsn = ENV["SENTRY_DSN"]
      config.environment = ENV.fetch("SENTRY_ENVIRONMENT", "orchestrator-production")
      config.release = ENV.fetch("SENTRY_RELEASE", "unknown")
      config.server_name = Socket.gethostname

      # Same wallet filtering as Rails app
      config.before_send = lambda do |event, _hint|
        # CRITICAL: Detect Monero wallet addresses and drop event
        monero_wallet_pattern = /4[0-9AB][1-9A-HJ-NP-Za-km-z]{93}/
        event_json = event.to_json

        if event_json.match?(monero_wallet_pattern)
          STDERR.puts "Sentry event contains Monero wallet - dropping for security"
          return nil
        end

        # Tag all events with component and hostname
        event.tags[:component] = "orchestrator"
        event.tags[:hostname] = Socket.gethostname
        event
      end

      # Disable in test/development
      config.enabled_environments = %w[production staging orchestrator-production]
    end
    STDERR.puts "Sentry initialized for orchestrator (#{Socket.gethostname})"
  rescue => e
    STDERR.puts "Failed to initialize Sentry: #{e.message}"
    STDERR.puts "Continuing without Sentry integration"
  end
else
  STDERR.puts "SENTRY_DSN not set - Sentry disabled for orchestrator"
end

class XmrigOrchestrator
  POLL_INTERVAL = 10 # seconds
  DB_PATH = ENV.fetch("XMRIG_DB_PATH", "/mnt/rails-storage/production.sqlite3")
  LOG_PATH = ENV.fetch("XMRIG_LOG_PATH", "/var/log/xmrig/orchestrator.log")
  XMRIG_API_URL = ENV.fetch("XMRIG_API_URL", "http://127.0.0.1:8080/2/summary")

  # Allowed columns for update_process_status (SQL injection protection)
  ALLOWED_PROCESS_COLUMNS = %w[
    status pid hostname worker_id started_at stopped_at error_count
    last_error last_health_check_at restart_count hashrate
    accepted_shares rejected_shares health_data
  ].freeze

  def initialize
    @hostname = Socket.gethostname
    @logger = Logger.new(LOG_PATH, "daily") # Daily rotation
    @logger.level = Logger::INFO
    @db = SQLite3::Database.new(DB_PATH)
    @db.results_as_hash = true

    # Enable WAL mode for better concurrency with Rails app
    @db.execute("PRAGMA journal_mode=WAL")
    @db.execute("PRAGMA synchronous=NORMAL")
    @db.execute("PRAGMA busy_timeout=5000")

    # Log monitoring configuration
    @xmrig_log_path = "/var/log/xmrig/xmrig.log"
    @log_file_handle = nil
    @log_file_position = 0
    @log_file_inode = nil
    @log_batch = []
    @last_flush_time = Time.now

    # Batch configuration
    @batch_flush_interval = 180  # 3 minutes
    @batch_max_size = 100
  end

  def run
    @logger.info "XMRig Orchestrator starting on #{@hostname}"
    @logger.info "Database: #{DB_PATH}"
    @logger.info "XMRig API: #{XMRIG_API_URL}"

    loop do
      begin
        process_pending_commands
        update_health_status
        monitor_xmrig_logs
        flush_logs_if_needed
        sleep POLL_INTERVAL
      rescue => e
        @logger.error "Error in main loop: #{e.message}"
        @logger.error e.backtrace.join("\n")

        # Capture orchestrator errors to Sentry too
        Sentry.capture_exception(e) if ENV["SENTRY_DSN"]

        sleep 30 # Back off on errors
      end
    end
  end

  private

  def monitor_xmrig_logs
    return unless ENV["SENTRY_DSN"]  # Skip if Sentry not configured
    return unless File.exist?(@xmrig_log_path)

    # Initialize file handle on first read
    if @log_file_handle.nil?
      begin
        @log_file_handle = File.open(@xmrig_log_path, "r")
        @log_file_position = @log_file_handle.size  # Start at end (don't read old logs)
        @log_file_inode = File.stat(@xmrig_log_path).ino
        @logger.info "Started monitoring XMRig logs: #{@xmrig_log_path}"
      rescue => e
        @logger.error "Failed to open XMRig log file: #{e.message}"
        return
      end
    end

    # Check for log rotation (inode change)
    begin
      current_inode = File.stat(@xmrig_log_path).ino
      if current_inode != @log_file_inode
        @logger.info "Log rotation detected, reopening file"
        @log_file_handle.close
        @log_file_handle = File.open(@xmrig_log_path, "r")
        @log_file_position = 0
        @log_file_inode = current_inode
      end
    rescue => e
      @logger.error "Error checking log file: #{e.message}"
      return
    end

    # Read new lines
    begin
      @log_file_handle.seek(@log_file_position)

      while line = @log_file_handle.gets
        process_log_line(line.strip)
      end

      @log_file_position = @log_file_handle.pos
    rescue => e
      @logger.error "Error reading log file: #{e.message}"
    end
  end

  def process_log_line(line)
    # Parse XMRig log format: [YYYY-MM-DD HH:MM:SS.mmm]  LEVEL  message
    # Only capture ERR and WARNING levels
    return unless line.match?(/\[[\d:\-\s.]+\]\s+(ERR|WARNING)\s+/)

    # Extract severity level
    severity = line.match(/\[[\d:\-\s.]+\]\s+(ERR|WARNING)/)[1]

    # Add to batch
    @log_batch << {
      line: line,
      severity: severity,
      timestamp: Time.now.utc.iso8601,
      hostname: @hostname
    }

    @logger.debug "Captured #{severity} log line (batch size: #{@log_batch.size})"

    # Flush immediately if batch is full
    flush_logs_to_sentry if @log_batch.size >= @batch_max_size
  end

  def flush_logs_if_needed
    return unless ENV["SENTRY_DSN"]
    return if @log_batch.empty?

    # Check time-based flush
    time_since_flush = Time.now - @last_flush_time

    if time_since_flush >= @batch_flush_interval
      flush_logs_to_sentry
    end
  end

  def flush_logs_to_sentry
    return if @log_batch.empty?

    begin
      @logger.info "Flushing #{@log_batch.size} log entries to Sentry"

      # Group by severity for better Sentry organization
      errors = @log_batch.select { |entry| entry[:severity] == "ERR" }
      warnings = @log_batch.select { |entry| entry[:severity] == "WARNING" }

      # Send errors
      unless errors.empty?
        send_batch_to_sentry(errors, :error)
      end

      # Send warnings
      unless warnings.empty?
        send_batch_to_sentry(warnings, :warning)
      end

      # Clear batch and update flush time
      @log_batch.clear
      @last_flush_time = Time.now

      @logger.info "Successfully flushed logs to Sentry"
    rescue => e
      @logger.error "Failed to flush logs to Sentry: #{e.message}"
      @logger.error e.backtrace.join("\n")

      # Clear batch anyway to prevent memory buildup
      @log_batch.clear
      @last_flush_time = Time.now
    end
  end

  def send_batch_to_sentry(batch, level)
    # Create summary message
    count = batch.size
    message = "XMRig #{level.upcase}: #{count} #{level}(s) in batch"

    Sentry.with_scope do |scope|
      scope.set_tag("component", "xmrig")
      scope.set_tag("hostname", @hostname)
      scope.set_level(level)

      # Add first few log lines as breadcrumbs for context
      batch.first(10).each do |entry|
        scope.add_breadcrumb(
          Sentry::Breadcrumb.new(
            category: "xmrig.log",
            message: entry[:line],
            level: level,
            timestamp: entry[:timestamp]
          )
        )
      end

      # Add all log lines as extra data
      scope.set_extra(:log_lines, batch.map { |e| e[:line] })
      scope.set_extra(:log_count, count)
      scope.set_extra(:log_file, @xmrig_log_path)
      scope.set_extra(:batch_period, "#{@batch_flush_interval}s")

      # Send to Sentry
      Sentry.capture_message(message)
    end
  end

  def process_pending_commands
    # Fetch and mark commands as processing within a transaction to prevent race conditions
    commands = @db.transaction do
      pending = @db.execute(
        "SELECT * FROM xmrig_commands WHERE status = 'pending' ORDER BY created_at ASC"
      )

      # Mark all pending commands as processing atomically
      pending.each do |cmd|
        @db.execute(
          "UPDATE xmrig_commands SET status = 'processing', processed_at = ? WHERE id = ?",
          [Time.now.utc.iso8601, cmd["id"]]
        )
      end

      pending
    end

    commands.each do |cmd|
      process_command(cmd)
    end
  end

  def process_command(cmd)
    @logger.info "Processing command: #{cmd['action']} (ID: #{cmd['id']})"

    # Command is already marked as processing by process_pending_commands transaction
    # Track whether we actually executed a command
    result, success = case cmd["action"]
    when "start"
      systemctl("start")
    when "stop"
      systemctl("stop")
    when "restart"
      systemctl("restart")
    else
      ["Unknown action: #{cmd['action']}", false]
    end

    if success
      @db.execute(
        "UPDATE xmrig_commands SET status = 'completed', result = ? WHERE id = ?",
        [result, cmd["id"]]
      )
      @logger.info "Command completed: #{cmd['action']}"
    else
      @db.execute(
        "UPDATE xmrig_commands SET status = 'failed', error_message = ? WHERE id = ?",
        [result, cmd["id"]]
      )
      @logger.error "Command failed: #{cmd['action']} - #{result}"
    end
  rescue => e
    @db.execute(
      "UPDATE xmrig_commands SET status = 'failed', error_message = ? WHERE id = ?",
      [e.message, cmd["id"]]
    )
    @logger.error "Command error: #{e.message}"
  end

  def systemctl(action)
    # Use array form to avoid shell injection (subprocess will exec directly)
    # Using sudo with NOPASSWD configuration for specific systemctl commands
    stdout, stderr, status = Open3.capture3('sudo', 'systemctl', action, 'xmrig')
    output = stdout + stderr

    # Return both output and success status
    [output, status.success?]
  end

  def update_health_status
    health = fetch_xmrig_health

    if health
      update_process_status(
        status: "running",
        pid: health["worker_id"],
        hashrate: health.dig("hashrate", "total", 0),
        accepted_shares: health.dig("results", "shares_good"),
        rejected_shares: health.dig("results", "shares_bad"),
        health_data: health.to_json
      )

      # Check for errors
      if health.dig("hashrate", "total", 0) == 0
        @logger.warn "Zero hashrate detected"
        check_and_restart_if_needed("zero_hashrate")
      end
    else
      # XMRig not responding
      status_output, _stderr, _status = Open3.capture3('sudo', 'systemctl', 'is-active', 'xmrig')
      status_output = status_output.strip

      if status_output == "active"
        update_process_status(status: "unhealthy")
        check_and_restart_if_needed("api_not_responding")
      else
        update_process_status(status: "stopped")
      end
    end
  rescue => e
    @logger.error "Health check error: #{e.message}"
  end

  def fetch_xmrig_health
    uri = URI(XMRIG_API_URL)

    # Set timeouts to prevent hanging on unresponsive API
    response = Net::HTTP.start(uri.host, uri.port,
                                open_timeout: 5,
                                read_timeout: 5,
                                write_timeout: 5) do |http|
      http.get(uri.path.empty? ? '/' : uri.path)
    end

    return nil unless response.is_a?(Net::HTTPSuccess)

    JSON.parse(response.body)
  rescue Errno::ECONNREFUSED, SocketError, JSON::ParserError, Net::OpenTimeout, Net::ReadTimeout => e
    @logger.debug "XMRig API not accessible: #{e.class}"
    nil
  end

  def update_process_status(attrs)
    attrs[:hostname] = @hostname
    attrs[:worker_id] ||= "#{@hostname}-production"
    attrs[:last_health_check_at] = Time.now.utc.iso8601

    # Filter to only allowed columns (SQL injection protection)
    safe_attrs = attrs.select { |k, _| ALLOWED_PROCESS_COLUMNS.include?(k.to_s) }

    if safe_attrs.empty?
      @logger.warn "No valid columns to update in update_process_status"
      return
    end

    existing = @db.execute(
      "SELECT id FROM xmrig_processes WHERE hostname = ?",
      [@hostname]
    ).first

    if existing
      set_clause = safe_attrs.map { |k, _| "#{k} = ?" }.join(", ")
      values = safe_attrs.values + [Time.now.utc.iso8601, existing["id"]]

      @db.execute(
        "UPDATE xmrig_processes SET #{set_clause}, updated_at = ? WHERE id = ?",
        values
      )
    else
      columns = safe_attrs.keys.join(", ")
      placeholders = (["?"] * safe_attrs.size).join(", ")

      @db.execute(
        "INSERT INTO xmrig_processes (#{columns}, created_at, updated_at) VALUES (#{placeholders}, ?, ?)",
        safe_attrs.values + [Time.now.utc.iso8601, Time.now.utc.iso8601]
      )
    end
  end

  def check_and_restart_if_needed(reason)
    # Immediate restart on any error (dedicated mining machines)
    @logger.warn "Error detected, issuing immediate restart: #{reason}"

    @db.execute(
      "INSERT INTO xmrig_commands (action, reason, status, created_at, updated_at) VALUES ('restart', ?, 'pending', ?, ?)",
      [reason, Time.now.utc.iso8601, Time.now.utc.iso8601]
    )

    @db.execute(
      "UPDATE xmrig_processes SET restart_count = restart_count + 1, error_count = error_count + 1, last_error = ? WHERE hostname = ?",
      [reason, @hostname]
    )
  end
end

# Signal handling for graceful shutdown
trap("INT") do
  puts "\nShutting down XMRig Orchestrator..."
  exit 0
end

trap("TERM") do
  puts "\nShutting down XMRig Orchestrator..."
  exit 0
end

# Run daemon
XmrigOrchestrator.new.run
